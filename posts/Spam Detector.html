<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Spam Detection – Justin Donaldson, Ph.D.</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/nav-logo.jpeg" rel="icon" type="image/jpeg">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-db9978a3e07bc668402620f3074672fa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-J1DD0F3VY9"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-J1DD0F3VY9', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../style.css">
<meta property="og:title" content="Spam Detection – Justin Donaldson, Ph.D.">
<meta property="og:description" content="">
<meta property="og:image" content="http://www.jjd.io/posts/images/spam_spam.png">
<meta property="og:site_name" content="Justin Donaldson, Ph.D.">
<meta property="og:image:height" content="512">
<meta property="og:image:width" content="512">
<meta name="twitter:title" content="Spam Detection – Justin Donaldson, Ph.D.">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="http://www.jjd.io/posts/images/spam_spam.png">
<meta name="twitter:site" content="@omgjjd">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="512">
<meta name="twitter:image-width" content="512">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/nav-logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Justin Donaldson, Ph.D.</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../cv.html"> 
<span class="menu-text">cv</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jdonaldson"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/omgjjd"> <i class="bi bi-twitter" role="img" aria-label="Twitter">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jjustindonaldson/"> <i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.discogs.com/user/omgjjd"> <i class="bi bi-vinyl-fill" role="img" aria-label="Discogs">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#step-1-define-scope" id="toc-step-1-define-scope" class="nav-link" data-scroll-target="#step-1-define-scope">Step 1 : Define Scope</a></li>
  <li><a href="#evolution-of-text-representation-models-size-and-capabilities" id="toc-evolution-of-text-representation-models-size-and-capabilities" class="nav-link" data-scroll-target="#evolution-of-text-representation-models-size-and-capabilities">Evolution of Text Representation Models: Size and Capabilities</a></li>
  <li><a href="#step-2.-install-dependencies" id="toc-step-2.-install-dependencies" class="nav-link" data-scroll-target="#step-2.-install-dependencies">Step 2. Install Dependencies</a>
  <ul class="collapse">
  <li><a href="#required-python-packages" id="toc-required-python-packages" class="nav-link" data-scroll-target="#required-python-packages">Required Python Packages</a></li>
  <li><a href="#recommended-install-miniconda" id="toc-recommended-install-miniconda" class="nav-link" data-scroll-target="#recommended-install-miniconda">Recommended: Install Miniconda</a>
  <ul class="collapse">
  <li><a href="#install-miniconda" id="toc-install-miniconda" class="nav-link" data-scroll-target="#install-miniconda"><strong>1. Install Miniconda</strong></a></li>
  <li><a href="#create-a-conda-environment" id="toc-create-a-conda-environment" class="nav-link" data-scroll-target="#create-a-conda-environment"><strong>2. Create a Conda Environment</strong></a></li>
  <li><a href="#install-required-packages" id="toc-install-required-packages" class="nav-link" data-scroll-target="#install-required-packages"><strong>3. Install Required Packages</strong></a></li>
  <li><a href="#verify-installation" id="toc-verify-installation" class="nav-link" data-scroll-target="#verify-installation"><strong>4. Verify Installation</strong></a></li>
  <li><a href="#launch-jupyterlab" id="toc-launch-jupyterlab" class="nav-link" data-scroll-target="#launch-jupyterlab"><strong>5. Launch JupyterLab</strong></a></li>
  </ul></li>
  <li><a href="#step-3-data-collection-and-processing" id="toc-step-3-data-collection-and-processing" class="nav-link" data-scroll-target="#step-3-data-collection-and-processing">Step 3: Data Collection and Processing</a></li>
  </ul></li>
  <li><a href="#step-4-feature-engineering" id="toc-step-4-feature-engineering" class="nav-link" data-scroll-target="#step-4-feature-engineering">Step 4: Feature Engineering</a></li>
  <li><a href="#step-5-model-selection" id="toc-step-5-model-selection" class="nav-link" data-scroll-target="#step-5-model-selection">Step 5: Model Selection</a></li>
  <li><a href="#step-6-training" id="toc-step-6-training" class="nav-link" data-scroll-target="#step-6-training">Step 6: Training</a></li>
  <li><a href="#step-7-evaluation" id="toc-step-7-evaluation" class="nav-link" data-scroll-target="#step-7-evaluation">Step 7: Evaluation</a></li>
  <li><a href="#future-steps" id="toc-future-steps" class="nav-link" data-scroll-target="#future-steps">Future Steps</a></li>
  <li><a href="#recommended-readings" id="toc-recommended-readings" class="nav-link" data-scroll-target="#recommended-readings">Recommended Readings</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Spam Detection</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="alert alert-info">
<p>Note: This document contains AI generated content - code and editing refinement provided by GPT-3 class models.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://youtu.be/aFUgG4zNuH4?si=FP2n7egpXyLxSI2O"><img src="images/spam_spam.png" class="img-fluid figure-img"></a></p>
<figcaption>Spam</figcaption>
</figure>
</div>
<p>(Click image above for link to <a href="https://www.youtube.com/watch?v=aFUgG4zNuH4">youtube video</a>)</p>
<p>Welcome to the Modeling Deep Dive Section of <strong>MLPROD 310.</strong></p>
<ul>
<li><a href="https://canvas.uw.edu/courses/1424648">Canvas Link</a></li>
<li><a href="https://www.pce.uw.edu/specializations/machine-learning-product-management">Course Information</a></li>
<li><a href="https://github.com/jdonaldson/jjd.io/blob/main/posts/Spam%20Detector.ipynb">Github Notebook Link</a></li>
<li><a href="https://colab.research.google.com/drive/1iddMNfcNRJZQpfzT08dfdg76uMA0ZLCc?usp=sharing">Colab Link</a></li>
</ul>
<p>This document is an overview of an example spam detection model, and how one might go about building a pipeline for training and evaluation of a simple spam detector using simple modeling components.</p>
<p>The notebook is broken down into several steps, and outlines some of the options/caveats that are inherent to the step. The notebook selects basic steps that build on simpler linear and neural network architectures, but don’t necessarily suggest that the chosen architectures are the “best” overall.</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Spam detection is the process of identifying and filtering unwanted or malicious messages, such as emails, SMS, or social media posts. Spam can range from harmless but annoying advertisements to dangerous phishing attempts and malware distribution. Given the vast volume of digital communication, automated spam detection systems are essential for maintaining security, efficiency, and user experience. This article walks through the construction of a spam classifier using open source models and tooling. The article itself is written as a jupyter notebook and rendered to html. The original jupyter notebook is avaialable <a href="https://github.com/jdonaldson/jjd.io/blob/main/posts/Spam%20Detector.ipynb">here</a></p>
<p>Building an optimal spam detection model involves multiple considerations, including data collection, feature selection, model choice, and evaluation. The decision-making process typically follows these key steps:</p>
<ol type="1">
<li><strong>Defining the Problem Scope</strong></li>
</ol>
<ul>
<li><p>What type of spam needs to be detected (emails, SMS, social media posts, etc.)?</p></li>
<li><p>What is the acceptable trade-off between false positives (legitimate messages flagged as spam) and false negatives (spam messages that get through)?</p></li>
</ul>
<ol start="2" type="1">
<li><strong>Data Collection and Preprocessing</strong></li>
</ol>
<ul>
<li><p>Gathering labeled datasets of spam and non-spam messages.</p></li>
<li><p>Cleaning the data by removing noise, tokenizing text, and handling missing values.</p></li>
<li><p>Augmenting data with additional signals like sender reputation, message structure, and frequency patterns.</p></li>
</ul>
<ol start="3" type="1">
<li><strong>Feature Engineering</strong></li>
</ol>
<ul>
<li><p>Extracting relevant features such as word frequency, n-grams, TF-IDF scores, or embeddings from NLP models.</p></li>
<li><p>Incorporating metadata features (e.g., sender history, link presence, HTML content).</p></li>
</ul>
<ol start="4" type="1">
<li><strong>Model Selection</strong></li>
</ol>
<ul>
<li><p>Choosing between rule-based systems, classical machine learning models (Naïve Bayes, SVMs, Random Forests), or deep learning approaches (LSTMs, Transformers).</p></li>
<li><p>Evaluating trade-offs between interpretability, computational cost, and effectiveness.</p></li>
</ul>
<ol start="5" type="1">
<li><strong>Training</strong></li>
</ol>
<ul>
<li>Splitting data into training, validation, and test sets.</li>
</ul>
<ol start="6" type="1">
<li><strong>Evaluation</strong></li>
</ol>
<ul>
<li><p>Using metrics like precision, recall, F1-score, and ROC-AUC to assess performance.</p></li>
<li><p>Implementing techniques like cross-validation and hyperparameter tuning to optimize the model.</p></li>
</ul>
</section>
<section id="step-1-define-scope" class="level2">
<h2 class="anchored" data-anchor-id="step-1-define-scope">Step 1 : Define Scope</h2>
<p>For the purposes of this exercise we’ll look at e-mail messages that contain known spam or non-spam (“ham”) messages.</p>
<p>There’s a variety of techniques that are useful for detecting spam, including</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF/IDF</a>
<ul>
<li>Collecting and comparing word and document frequencies of spam/non-spam sources and creating message vectors.</li>
<li>Pros : Easy conceptual components, requires understanding of information entropy.</li>
<li>Cons : Doesn’t handle typos or unknown words well, normalized vectors can be enormous.</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Word_embedding">Word Embedding</a> (Concatenated)
<ul>
<li>Creating/Using word embeddings such as Word2Vec and concatenating into a message embedding.</li>
<li>Pros: 10-100x faster than sentence embeddings. Effective for simple descriptive phases.</li>
<li>Cons: Concatenated word embeddings can lose a lot of precision with even a handful of concatenated word vectors.</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Sentence_embedding">Sentence Embedding</a>
<ul>
<li>Creating/Using sentence embeddings such as SentenceBert into message embeddings.</li>
<li>Pros: 10-100x faster than instruction embeddings. Effective for capturing complex semantic sentence structure.</li>
<li>Cons: Not nearly as fast as word embeddings, nor are they capable of handling specific instructions.</li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)">Transformer Embedding</a> (GPT &gt;=3)
<ul>
<li>Creating/Using instruction embeddings from larger models.</li>
<li>Pros: Possible to “program” embeddings using special instructions (give instructions that give more clear separation between records based on context).</li>
<li>Cons: Much more expensive and time consuming to execute.</li>
</ul></li>
</ul>
</section>
<section id="evolution-of-text-representation-models-size-and-capabilities" class="level1">
<h1>Evolution of Text Representation Models: Size and Capabilities</h1>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 24%">
<col style="width: 14%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th>Model Type</th>
<th>Typical Size</th>
<th>Dimensionality</th>
<th>Context Window</th>
<th>Training Data Requirements</th>
<th>Key Capabilities</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>TF-IDF</strong></td>
<td>Very small<br>(KB to MB)</td>
<td>Sparse vectors<br>(Dictionary size)</td>
<td>Document/corpus level</td>
<td>Minimal<br>(Just the target corpus)</td>
<td>• Simple statistical word importance<br>• Effective for document classification<br>• Computationally efficient<br>• No pre-training required</td>
<td>• No semantic understanding<br>• No word relationships<br>• Sparse representation<br>• Fixed vocabulary</td>
</tr>
<tr class="even">
<td><strong>Word Vectors</strong><br>(word2vec, GloVe)</td>
<td>Small<br>(100MB-1GB)</td>
<td>Dense vectors<br>(50-300)</td>
<td>Word level</td>
<td>Medium<br>(1B+ tokens)</td>
<td>• Captures semantic relationships<br>• Word analogies (king - man + woman = queen)<br>• Transfer learning for downstream tasks<br>• Efficient inference</td>
<td>• Static word representations<br>• No context sensitivity<br>• No sentence-level understanding<br>• Word ambiguity issues</td>
</tr>
<tr class="odd">
<td><strong>Sentence Embeddings</strong><br>(USE, InferSent, SBERT)</td>
<td>Medium<br>(1-5GB)</td>
<td>Dense vectors<br>(512-1024)</td>
<td>Sentence level</td>
<td>Large<br>(10B+ tokens)</td>
<td>• Sentence-level semantics<br>• Better for similarity tasks<br>• Cross-lingual capabilities<br>• Effective for retrieval</td>
<td>• Limited contextual understanding<br>• Fixed-length representations<br>• Less effective for long documents<br>• Limited compositional abilities</td>
</tr>
<tr class="even">
<td><strong>Small Transformers</strong><br>(BERT-base, RoBERTa-base)</td>
<td>Medium<br>(0.5-1GB)</td>
<td>Contextual vectors<br>(768-1024)</td>
<td>Limited<br>(512 tokens)</td>
<td>Very large<br>(30B+ tokens)</td>
<td>• Contextual word representations<br>• Bidirectional context<br>• Strong performance on many NLP tasks<br>• Fine-tuning capabilities</td>
<td>• Limited context window<br>• Moderate parameter efficiency<br>• Training compute requirements<br>• Still primarily linguistic understanding</td>
</tr>
<tr class="odd">
<td><strong>Large Transformers</strong><br>(GPT-3, PaLM, Claude)</td>
<td>Very large<br>(100GB-1TB+)</td>
<td>Contextual vectors<br>(2048-12288+)</td>
<td>Large<br>(8K-100K+ tokens)</td>
<td>Massive<br>(1T+ tokens)</td>
<td>• Few/zero-shot learning<br>• Long-range dependencies<br>• Emergent abilities<br>• Cross-task generalization<br>• Natural language generation</td>
<td>• Enormous compute requirements<br>• Training cost<br>• Potential for biased outputs<br>• “Black box” behavior<br>• Challenging to interpret</td>
</tr>
</tbody>
</table>
<div id="27a0c328-f925-4d94-937a-3f04a3a95c5b" class="cell" data-tags="[]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> FuncFormatter</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame with model data</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'name'</span>: [<span class="st">'TF-IDF'</span>, <span class="st">'Word2Vec'</span>, <span class="st">'GloVe'</span>, <span class="st">'BERT-base'</span>, <span class="st">'RoBERTa'</span>, <span class="st">'GPT-2'</span>, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>             <span class="st">'T5-large'</span>, <span class="st">'GPT-3'</span>, <span class="st">'PaLM'</span>, <span class="st">'GPT-4'</span>],</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'year'</span>: [<span class="dv">2000</span>, <span class="dv">2013</span>, <span class="dv">2014</span>, <span class="dv">2018</span>, <span class="dv">2019</span>, <span class="dv">2019</span>, <span class="dv">2020</span>, <span class="dv">2020</span>, <span class="dv">2022</span>, <span class="dv">2023</span>],</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'size'</span>: [<span class="fl">0.001</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">1.5</span>, <span class="dv">3</span>, <span class="dv">175</span>, <span class="dv">540</span>, <span class="dv">1500</span>],  <span class="co"># Size in GB</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'capability'</span>: [</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Basic word importance/Document classification'</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Word relationships/Word analogies'</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Global corpus statistics/Improved semantic capture'</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Contextual representation/Bidirectional understanding'</span>,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Optimized pre-training/State-of-art on benchmarks'</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Better text generation/Zero-shot learning'</span>,</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Text-to-text framework/Multi-task learning'</span>,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Few-shot learning/Complex instructions'</span>,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Chain-of-thought reasoning/Advanced problem solving'</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Nuanced reasoning/Multimodal understanding'</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by year for proper timeline</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.sort_values(by<span class="op">=</span>[<span class="st">'year'</span>, <span class="st">'size'</span>])</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure and axis</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.subplot(<span class="dv">111</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot with log scale for y-axis to handle the dramatic size differences</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>ax.semilogy(df[<span class="st">'year'</span>], df[<span class="st">'size'</span>], marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'#2563eb'</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Format y-axis to show values nicely</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> size_formatter(x, pos):</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x <span class="op">&lt;</span> <span class="dv">1</span>:</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span>x<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span><span class="bu">int</span>(x) <span class="cf">if</span> x <span class="op">==</span> <span class="bu">int</span>(x) <span class="cf">else</span> x<span class="sc">:.1f}</span><span class="ss">"</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>ax.yaxis.set_major_formatter(FuncFormatter(size_formatter))</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Add annotations for each model</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine annotation placement (above or below point based on position)</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row[<span class="st">'size'</span>] <span class="op">&gt;</span> <span class="dv">10</span>:</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        y_offset <span class="op">=</span> <span class="op">-</span><span class="fl">1.2</span>  <span class="co"># Place below for large models</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        va <span class="op">=</span> <span class="st">'top'</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        y_offset <span class="op">=</span> <span class="fl">1.2</span>  <span class="co"># Place above for small models</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        va <span class="op">=</span> <span class="st">'bottom'</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add model name</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    ax.annotate(</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>row[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        xy<span class="op">=</span>(row[<span class="st">'year'</span>], row[<span class="st">'size'</span>]),</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>        xytext<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">20</span> <span class="op">*</span> y_offset),</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>        textcoords<span class="op">=</span><span class="st">"offset points"</span>,</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        ha<span class="op">=</span><span class="st">'center'</span>,</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>        va<span class="op">=</span>va,</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        fontweight<span class="op">=</span><span class="st">'bold'</span>,</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">9</span>,</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">"round,pad=0.3"</span>, fc<span class="op">=</span><span class="st">"white"</span>, ec<span class="op">=</span><span class="st">"gray"</span>, alpha<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add capability text in smaller font</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>    ax.annotate(</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>row[<span class="st">'capability'</span>]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        xy<span class="op">=</span>(row[<span class="st">'year'</span>], row[<span class="st">'size'</span>]),</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        xytext<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">45</span> <span class="op">*</span> y_offset),</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        textcoords<span class="op">=</span><span class="st">"offset points"</span>,</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>        ha<span class="op">=</span><span class="st">'center'</span>,</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>        va<span class="op">=</span>va,</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">"round,pad=0.3"</span>, fc<span class="op">=</span><span class="st">"#f0f7ff"</span>, ec<span class="op">=</span><span class="st">"#c7dbff"</span>, alpha<span class="op">=</span><span class="fl">0.9</span>),</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>        wrap<span class="op">=</span><span class="va">True</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels and title</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Year'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Model Size (GB)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Growth in NLP Model Size (2000-2023)'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Add grid for better readability (especially with log scale)</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">"both"</span>, ls<span class="op">=</span><span class="st">"-"</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the x-axis to give some padding</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> df[<span class="st">'year'</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, df[<span class="st">'year'</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>plt.xlim(x_min, x_max)</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a note about log scale</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>plt.figtext(<span class="fl">0.5</span>, <span class="fl">0.01</span>, </span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>           <span class="st">"Note: Y-axis uses logarithmic scale to visualize the exponential growth in model size"</span>, </span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>           ha<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">9</span>, style<span class="op">=</span><span class="st">'italic'</span>)</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Layout adjustment to make space for annotations</span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="fl">0.03</span>, <span class="dv">1</span>, <span class="fl">0.95</span>])</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the figure</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'nlp_model_size_growth.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the data as a table</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">NLP Model Size and Capability Data:"</span>)</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[[<span class="st">'name'</span>, <span class="st">'year'</span>, <span class="st">'size'</span>, <span class="st">'capability'</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Spam Detector_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
NLP Model Size and Capability Data:
     name  year     size                                            capability
   TF-IDF  2000    0.001         Basic word importance/Document classification
 Word2Vec  2013    0.300                     Word relationships/Word analogies
    GloVe  2014    0.500    Global corpus statistics/Improved semantic capture
BERT-base  2018    0.400 Contextual representation/Bidirectional understanding
  RoBERTa  2019    0.500     Optimized pre-training/State-of-art on benchmarks
    GPT-2  2019    1.500             Better text generation/Zero-shot learning
 T5-large  2020    3.000            Text-to-text framework/Multi-task learning
    GPT-3  2020  175.000                Few-shot learning/Complex instructions
     PaLM  2022  540.000   Chain-of-thought reasoning/Advanced problem solving
    GPT-4  2023 1500.000            Nuanced reasoning/Multimodal understanding</code></pre>
</div>
</div>
<div id="6a444142-95f5-4749-ada6-35c29a0b32bd" class="cell" data-tags="[]" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">## If you have jupyter lab running already, just uncomment this cell to install what you need.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install polars sentence-transformers tqdm pyarrow altair ipywidgets pandas matplotlib</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-2.-install-dependencies" class="level1">
<h1>Step 2. Install Dependencies</h1>
<section id="required-python-packages" class="level2">
<h2 class="anchored" data-anchor-id="required-python-packages">Required Python Packages</h2>
<p>The following Python packages are needed for the project:</p>
<ul>
<li><a href="https://pola.rs/"><code>polars</code></a> – Fast DataFrame library<br>
</li>
<li><a href="https://www.sbert.net/"><code>sentence-transformers</code></a> – Pre-trained models for sentence embeddings<br>
</li>
<li><a href="https://tqdm.github.io/"><code>tqdm</code></a> – Progress bar library<br>
</li>
<li><a href="https://arrow.apache.org/docs/python/"><code>pyarrow</code></a> – Apache Arrow for fast data processing<br>
</li>
<li><a href="https://altair-viz.github.io/"><code>altair</code></a> – Declarative statistical visualization library<br>
</li>
<li><a href="https://ipywidgets.readthedocs.io/en/stable/"><code>ipywidgets</code></a> – Interactive widgets for Jupyter notebooks<br>
</li>
<li><a href="https://pandas.pydata.org/"><code>pandas</code></a> – Data analysis library<br>
</li>
<li><a href="https://matplotlib.org/"><code>matplotlib</code></a> – Visualization library</li>
</ul>
<p>We will call out specific libraries and their strengths and weaknesses.</p>
</section>
<section id="recommended-install-miniconda" class="level2">
<h2 class="anchored" data-anchor-id="recommended-install-miniconda">Recommended: Install Miniconda</h2>
<p>Using Miniconda is highly recommended to manage dependencies efficiently. Follow the instructions below to install Miniconda and set up an environment.</p>
<section id="install-miniconda" class="level3">
<h3 class="anchored" data-anchor-id="install-miniconda"><strong>1. Install Miniconda</strong></h3>
<section id="mac-linux" class="level4">
<h4 class="anchored" data-anchor-id="mac-linux"><strong>Mac &amp; Linux</strong></h4>
<p>Run the following commands in a terminal:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download Miniconda installer</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh <span class="at">-O</span> miniconda.sh</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># OR for macOS (Intel)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh <span class="at">-O</span> miniconda.sh</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># OR for macOS (Apple Silicon)</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh <span class="at">-O</span> miniconda.sh</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Install Miniconda</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> miniconda.sh <span class="at">-b</span> <span class="at">-p</span> <span class="va">$HOME</span>/miniconda</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Conda</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="va">$HOME</span><span class="ex">/miniconda/bin/conda</span> init</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Restart your terminal for the changes to take effect.</p>
</section>
<section id="windows" class="level4">
<h4 class="anchored" data-anchor-id="windows"><strong>Windows</strong></h4>
<ol type="1">
<li><p>Download the latest <a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe">Miniconda installer</a>.</p></li>
<li><p>Run the installer and follow the on-screen instructions.</p></li>
<li><p>Open <strong>Anaconda Prompt</strong> or <strong>PowerShell</strong>, then initialize Conda:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode powershell code-with-copy"><code class="sourceCode powershell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>conda init</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
<p>Restart your terminal or PowerShell session.</p>
</section>
</section>
<section id="create-a-conda-environment" class="level3">
<h3 class="anchored" data-anchor-id="create-a-conda-environment"><strong>2. Create a Conda Environment</strong></h3>
<p>Create and activate a new environment named <code>myenv</code> (or another name of your choice):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> myenv python=3.10 <span class="at">-y</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate myenv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="install-required-packages" class="level3">
<h3 class="anchored" data-anchor-id="install-required-packages"><strong>3. Install Required Packages</strong></h3>
<p>With the Conda environment activated, install the required packages:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install polars sentence-transformers tqdm pyarrow altair ipywidgets pandas matplotlib</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="verify-installation" class="level3">
<h3 class="anchored" data-anchor-id="verify-installation"><strong>4. Verify Installation</strong></h3>
<p>To check that everything is installed correctly, run:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-c</span> <span class="st">"import polars, sentence_transformers, tqdm, pyarrow, altair, ipywidgets, pandas, matplotlib; print('All packages installed successfully!')"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="launch-jupyterlab" class="level3">
<h3 class="anchored" data-anchor-id="launch-jupyterlab"><strong>5. Launch JupyterLab</strong></h3>
<p>To start JupyterLab, run:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> lab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You should see this notebook :)</p>
</section>
</section>
<section id="step-3-data-collection-and-processing" class="level2">
<h2 class="anchored" data-anchor-id="step-3-data-collection-and-processing">Step 3: Data Collection and Processing</h2>
<div id="0e78262a-0521-4de9-8fb7-c7ad3a5df48f" class="cell" data-tags="[]" data-execution_count="3">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> polars <span class="im">as</span> pl</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pl.read_csv(<span class="st">"https://raw.githubusercontent.com/bigmlcom/python/refs/heads/master/data/spam.csv"</span>, separator <span class="op">=</span> <span class="st">"</span><span class="ch">\t</span><span class="st">"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (5, 2)</small>
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Type</th>
<th data-quarto-table-cell-role="th">Message</th>
</tr>
<tr class="even">
<th>str</th>
<th>str</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>"ham"</td>
<td>"Go until jurong point, crazy..…</td>
</tr>
<tr class="even">
<td>"ham"</td>
<td>"Ok lar... Joking wif u oni..."</td>
</tr>
<tr class="odd">
<td>"spam"</td>
<td>"Free entry in 2 a wkly comp to…</td>
</tr>
<tr class="even">
<td>"ham"</td>
<td>"U dun say so early hor... U c …</td>
</tr>
<tr class="odd">
<td>"ham"</td>
<td>"Nah I don't think he goes to u…</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="step-4-feature-engineering" class="level1">
<h1>Step 4: Feature Engineering</h1>
<p>Let’s try <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">MiniLM</a>, a lightweight sentence embedding model.</p>
<p>We can create embeddings from the messages, and insert them back into the dataset as a separate column. Note how Jupyter allows one to use typed (f32x384) vectors as a column type. Pandas can not do this, and is one of the reasons Polars is recommended. However, Polars is still very new and is rapidly evolving. Make sure to stay <a href="https://pola.rs/">up to date on documentation</a>.</p>
<div id="7334c99b-d9bf-49a9-b9f6-8a0094e826a5" class="cell" data-tags="[]" data-execution_count="4">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>sentence_model <span class="op">=</span> SentenceTransformer(<span class="st">"all-MiniLM-L6-v2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="dfc10a78-1856-4924-808c-08222a37062c" class="cell" data-tags="[]" data-execution_count="5">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the embeddings and save them efficiently as a numpy array</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> sentence_model.encode(df[<span class="st">"Message"</span>].to_numpy())</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Bind the numpy array to the rest of the dataframe</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.with_columns([</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    pl.Series(embeddings).alias(<span class="st">"Message_Embeddings"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (5, 3)</small>
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Type</th>
<th data-quarto-table-cell-role="th">Message</th>
<th data-quarto-table-cell-role="th">Message_Embeddings</th>
</tr>
<tr class="even">
<th>str</th>
<th>str</th>
<th>array[f32, 384]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>"ham"</td>
<td>"Go until jurong point, crazy..…</td>
<td>[-0.016918, -0.038168, … -0.001258]</td>
</tr>
<tr class="even">
<td>"ham"</td>
<td>"Ok lar... Joking wif u oni..."</td>
<td>[-0.013369, -0.04987, … -0.003396]</td>
</tr>
<tr class="odd">
<td>"spam"</td>
<td>"Free entry in 2 a wkly comp to…</td>
<td>[-0.015434, 0.063041, … 0.015645]</td>
</tr>
<tr class="even">
<td>"ham"</td>
<td>"U dun say so early hor... U c …</td>
<td>[-0.012308, 0.037198, … -0.003828]</td>
</tr>
<tr class="odd">
<td>"ham"</td>
<td>"Nah I don't think he goes to u…</td>
<td>[0.0777, -0.132872, … 0.009034]</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="step-5-model-selection" class="level1">
<h1>Step 5: Model Selection</h1>
<p>There’s a number of different approaches we could take, but for the purposes of illustration, one has landed on using a simpler linear model on top of sentence embeddings.</p>
<div id="290b323f-f070-429a-befd-2c8372270ae2" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define logistic regression model</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogisticRegression(nn.Module):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(LogisticRegression, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(input_dim, <span class="dv">1</span>)  <span class="co"># Single output node</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigmoid <span class="op">=</span> nn.Sigmoid()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.sigmoid(<span class="va">self</span>.linear(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-6-training" class="level1">
<h1>Step 6: Training</h1>
<p>We will define a training loop. Since we are borrowing a sentence embedder with MiniLM, we don’t need to train a new one. However, we will need to train a simpler linear model.</p>
<p>We need to call out some specific choices here:</p>
<ul>
<li>criterion - choice of “loss” function, in this case <a href="https://en.wikipedia.org/wiki/Cross-entropy">binary cross entropy (BCE)</a>.</li>
<li>optimizer - choice of step function, in this case (most cases) <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">adam</a>.</li>
<li>epoch - number of complete passes through the data that the training routine has completed.</li>
</ul>
<div id="bc7ed946-5c69-4f02-af24-21ace9460e2d" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This cell contains a mix of AI and Human Generated Code.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> polars <span class="im">as</span> pl</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, f1_score</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert labels to binary (spam = 1, ham = 0) and keep as a Polars expression</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.with_columns((pl.col(<span class="st">"Type"</span>) <span class="op">==</span> <span class="st">"spam"</span>).cast(pl.Int32).alias(<span class="st">"Label"</span>))</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert Polars columns directly to PyTorch tensors</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.tensor(df[<span class="st">"Message_Embeddings"</span>], dtype<span class="op">=</span>torch.float32)  <span class="co"># Embeddings tensor</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df[<span class="st">"Label"</span>], dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>)  <span class="co"># Labels tensor</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into train and test sets</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize model</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> X.shape[<span class="dv">1</span>]  <span class="co"># Get embedding size</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(input_dim)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Define loss and optimizer</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.BCELoss()  <span class="co"># Binary cross-entropy loss</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>holdout_metrics <span class="op">=</span> []</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(X_train)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(outputs, y_train)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate the model on the holdout</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_test)</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>            holdout_loss <span class="op">=</span> criterion(y_pred, y_test)</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>            y_pred_labels <span class="op">=</span> (y_pred <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()  <span class="co"># Convert probabilities to binary (0 or 1)</span></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert tensors to NumPy arrays for sklearn metrics</span></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>        y_test_np <span class="op">=</span> y_test.numpy()</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>        y_pred_np <span class="op">=</span> y_pred_labels.numpy()</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute evaluation metrics</span></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(y_test_np, y_pred_np)</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">"epoch"</span> : epoch,</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>            <span class="st">"loss"</span> : loss.item(),</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>            <span class="st">"holdout_loss"</span> : holdout_loss.item(),</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>            <span class="st">"holdout_accuracy"</span> : accuracy,</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>        holdout_metrics.append(metrics)</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> pd.DataFrame(holdout_metrics).set_index(<span class="st">"epoch"</span>)</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">loss</th>
<th data-quarto-table-cell-role="th">holdout_loss</th>
<th data-quarto-table-cell-role="th">holdout_accuracy</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.666757</td>
<td>0.643077</td>
<td>0.878788</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10</td>
<td>0.472433</td>
<td>0.468307</td>
<td>0.878788</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">20</td>
<td>0.363610</td>
<td>0.375695</td>
<td>0.878788</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">30</td>
<td>0.300856</td>
<td>0.325027</td>
<td>0.878788</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">40</td>
<td>0.258253</td>
<td>0.291411</td>
<td>0.886364</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50</td>
<td>0.226611</td>
<td>0.266079</td>
<td>0.901515</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">60</td>
<td>0.202605</td>
<td>0.246158</td>
<td>0.924242</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">70</td>
<td>0.183906</td>
<td>0.230198</td>
<td>0.939394</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">80</td>
<td>0.168782</td>
<td>0.217127</td>
<td>0.939394</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">90</td>
<td>0.156178</td>
<td>0.206159</td>
<td>0.939394</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="step-7-evaluation" class="level1">
<h1>Step 7: Evaluation</h1>
<p>We come to the all important evaluation step. We need to assess the results and determine if the model is optimized.</p>
<ol type="1">
<li>We need to compare the loss metrics. What does loss mean, exactly? Does the loss metrics make sense? (Are they going down, is one loss better than the other? Why?)</li>
<li>The holdout accuracy looks like 88%, which seems good. Is it good enough? What are some simple things we can do to make it better just by looking at the chart?</li>
</ol>
<div id="8a04ad18-f01c-4f3b-b3ee-4aedc2b9850a" class="cell" data-tags="[]" data-execution_count="25">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>metrics.plot(title<span class="op">=</span><span class="st">"Holdout Training Metrics by Epoch"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Spam Detector_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="future-steps" class="level1">
<h1>Future Steps</h1>
<p>At this point, a decision is reached whether to release the model as-is, or think of ways of improving performance.</p>
<ol type="1">
<li>What are some pieces of information that could be added to the training embedding/vector? How?</li>
<li>What do we need to do to maintain this model? How would we detect model drift?</li>
<li>If we need to change from a binary classification model to a multi-class model, what needs to change? What <a href="https://en.wikipedia.org/wiki/Precision_and_recall">metrics</a> should be used?</li>
</ol>
</section>
<section id="recommended-readings" class="level1">
<h1>Recommended Readings</h1>
<ol type="1">
<li><a href="https://colah.github.io/posts/2015-09-Visual-Information/">Chris Olah’s Blog Post on Visual Information</a></li>
<li><a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A Visual Introduction to Machine Learning</a></li>
<li><a href="https://distill.pub/">Distill.pub</a></li>
</ol>


</section>

<p><i>© Copyright 2024 Justin Donaldson. Except where otherwise noted, all rights reserved. The views and opinions on this website are my own and do not represent my current or former employers.</i></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("http:\/\/www\.jjd\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>