{
 "cells": [
  {
   "cell_type": "raw",
   "id": "659f5c80-09d6-4b98-9ab8-668a2f738ce5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"From Words to Vectors: The Journey of Neural Word Embeddings\"\n",
    "description: \"Word embeddings transform individual words into dense numerical vectors in a high-dimensional space, where geometric relationships mirror semantic meaning. Through neural network training that learns from how words appear together in context, the system converts simple tokenized text into rich representations where similar words cluster together and vector arithmetic can reveal complex relationships. This mathematical model of language meaning enables machines to understand the nuanced connections between words that humans grasp intuitively, powering a wide range of natural language processing applications.\"\n",
    "author: \"Justin Donaldson\"\n",
    "date: \"2/14/2025\"\n",
    "\n",
    "categories:\n",
    "  - Neural Networks\n",
    "  - Embeddings\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e637b-b1a3-4b54-b5d8-581939074dce",
   "metadata": {},
   "source": [
    "# What Are Embeddings?\n",
    "\n",
    "Embeddings are numerical representations of objects (such as words, sentences, or images) in a continuous vector space. These representations capture semantic meaning, making it possible for machines to understand and compare them. \n",
    "\n",
    "\n",
    "```{mermaid}\n",
    "graph LR\n",
    "    %% Main embedding concepts\n",
    "    E[Embeddings] --> SE[Sentence Embeddings]\n",
    "    E --> ME[Multi-Modal Embeddings]\n",
    "    E --> DE[Document Embeddings]\n",
    "    \n",
    "    %% Media types\n",
    "    MT[Media Types] --> T[Text]\n",
    "    MT --> I[Images]\n",
    "    MT --> A[Audio]\n",
    "    MT --> V[Video]\n",
    "    \n",
    "    %% Embedding techniques for different media\n",
    "    T --> TE[Text Embeddings]\n",
    "    T --> SE\n",
    "    I --> IE[Image Embeddings]\n",
    "    A --> AE[Audio Embeddings]\n",
    "    V --> VE[Video Embeddings]\n",
    "    \n",
    "    %% Relationships between embeddings\n",
    "    TE --> ME\n",
    "    IE --> ME\n",
    "    AE --> ME\n",
    "    VE --> ME\n",
    "    \n",
    "    %% Cross-modal connections\n",
    "    ME --> CR[Cross-Modal Retrieval]\n",
    "    ME --> MS[Multi-Modal Search]\n",
    "    \n",
    "    %% Properties\n",
    "    style E fill:#f9f,stroke:#333\n",
    "    style MT fill:#bbf,stroke:#333\n",
    "    style ME fill:#bfb,stroke:#333\n",
    "    style CR fill:#fbb,stroke:#333\n",
    "    style MS fill:#fbb,stroke:#333\n",
    "```\n",
    "\n",
    "1. The core concept of embeddings branches into three main types:\n",
    "   - Sentence embeddings (specialized for text)\n",
    "   - Multi-modal embeddings (can handle multiple types of media)\n",
    "   - Document embeddings (for longer text)\n",
    "\n",
    "2. Different media types (text, images, audio, video) each have their own specialized embedding techniques\n",
    "\n",
    "3. All these individual embedding types can feed into multi-modal embeddings, which enable:\n",
    "   - Cross-modal retrieval (finding related content across different media types)\n",
    "   - Multi-modal search (searching across different types of media simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842429a-3a12-44ab-97f7-43b8da716265",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart TD\n",
    "    subgraph Input[Input Processing]\n",
    "        T[Text Input] --> TOK[Tokenization]\n",
    "        TOK --> VOC[Vocabulary Creation]\n",
    "        VOC --> OHE[One-Hot Encoding]\n",
    "    end\n",
    "\n",
    "    subgraph Training[Training Process]\n",
    "        OHE --> NNI[Neural Network Input Layer]\n",
    "        NNI --> HID[Hidden Layer]\n",
    "        HID --> CTX[Context Learning]\n",
    "        \n",
    "        subgraph Context[Context Window]\n",
    "            CW[Sliding Window]\n",
    "            TW[Target Word]\n",
    "            SW[Surrounding Words]\n",
    "        end\n",
    "        \n",
    "        CTX --> OPT[Optimization]\n",
    "        OPT --> LSF[Loss Function]\n",
    "        LSF --> BP[Backpropagation]\n",
    "        BP --> UP[Update Weights]\n",
    "    end\n",
    "\n",
    "    subgraph Output[Embedding Result]\n",
    "        UP --> WV[Word Vectors]\n",
    "        WV --> VS[Vector Space]\n",
    "        VS --> SIM[Semantic Similarities]\n",
    "        \n",
    "        SIM --> |Similar words cluster together| REL[Related Words]\n",
    "        SIM --> |Vector arithmetic possible| ANA[Analogies]\n",
    "        SIM --> |Distance measures similarity| DIS[Word Relationships]\n",
    "    end\n",
    "\n",
    "    style Input fill:#e1f3ff,stroke:#333\n",
    "    style Training fill:#fff3e1,stroke:#333\n",
    "    style Output fill:#e1ffe1,stroke:#333\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9ec48-03aa-4d3d-8a2a-3050ddc107d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
